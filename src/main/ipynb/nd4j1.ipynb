{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.addPath(\"/opt/app/libs/datavec-api-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/annotations-2.0.1.jar\")                \n",
    "classpath.addPath(\"/opt/app/libs/commons-io-2.4.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-0.5.0-linux-x86_64.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/commons-lang3-3.3.1.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/commons-math3-3.4.1.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/guava-18.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/javacpp-1.2.3.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-api-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/javassist-3.18.2-GA.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-platform-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/lombok-1.16.4.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/reflections-0.9.10.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-api-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/scala-library-2.11.1.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-buffer-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/slf4j-api-1.7.21.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-common-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/slf4j-simple-1.7.21.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-context-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/deeplearning4j-core-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/canova-api-0.0.0.17.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/hadoop-mapreduce-client-core-2.2.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/datavec-nd4j-common-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/reflections-0.9.10.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-dataformat-yaml-2.4.4.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/guava-18.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-core-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-annotations-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-databind-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-module-scala_2.10-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/json4s-jackson_2.10-3.2.11.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/commons-lang-2.5.jar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0 artifact(s)"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add(\"com.quantifind\" %% \"wisp\" % \"0.0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mjava.text.{DecimalFormat, DecimalFormatSymbols}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.commons.lang.StringUtils\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.api.complex.IComplexNDArray\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.api.ndarray.INDArray\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mNDArrayStrings\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.text.{DecimalFormat, DecimalFormatSymbols}\n",
    "\n",
    "import org.apache.commons.lang.StringUtils\n",
    "import org.nd4j.linalg.api.complex.IComplexNDArray\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "\n",
    "/**\n",
    "  * Created by claytongraham on 10/29/16.\n",
    "  */\n",
    "class NDArrayStrings {\n",
    "  private var sep: String = \",\"\n",
    "  private var padding: Int = 0\n",
    "  private var decFormatNum: String = \"#,###,##0\"\n",
    "  private var decFormatRest: String = \"\"\n",
    "  private var decimalFormat: DecimalFormat = new DecimalFormat(decFormatNum + decFormatRest)\n",
    "\n",
    "  def this(sep: String, precisionI: Int, decFormat: String) {\n",
    "    this()\n",
    "    this.decFormatNum = decFormat\n",
    "    this.sep = sep\n",
    "    var precision: Int = precisionI\n",
    "\n",
    "    if (precision != 0) {\n",
    "      this.decFormatRest = \".\"\n",
    "      while (precision > 0) {\n",
    "        this.decFormatRest += \"0\"\n",
    "        precision -= 1\n",
    "      }\n",
    "    }\n",
    "    this.decimalFormat = new DecimalFormat(decFormatNum + decFormatRest)\n",
    "    val sepNgroup: DecimalFormatSymbols = DecimalFormatSymbols.getInstance\n",
    "    sepNgroup.setDecimalSeparator('.')\n",
    "    sepNgroup.setGroupingSeparator(',')\n",
    "    decimalFormat.setDecimalFormatSymbols(sepNgroup)\n",
    "  }\n",
    "\n",
    "\n",
    "  /**\n",
    "    * Format the given ndarray as a string\n",
    "    *\n",
    "    * @param arr the array to format\n",
    "    * @return the formatted array\n",
    "    */\n",
    "  def format(arr: INDArray): String = {\n",
    "    val padding: String = decimalFormat.format(arr.maxNumber)\n",
    "    this.padding = padding.length\n",
    "    format(arr, arr.rank)\n",
    "  }\n",
    "\n",
    "  private def format(arr: INDArray, rank: Int): String = format(arr, arr.rank, 0)\n",
    "\n",
    "  private def format(arr: INDArray, rank: Int, offsetI: Int): String = {\n",
    "    val sb: StringBuilder = new StringBuilder\n",
    "    var offset: Int = offsetI\n",
    "    if (arr.isScalar) {\n",
    "      if (arr.isInstanceOf[IComplexNDArray]) return arr.asInstanceOf[IComplexNDArray].getComplex(0).toString\n",
    "      decimalFormat.format(arr.getDouble(0))\n",
    "    }\n",
    "    else if (rank <= 0) \"\"\n",
    "    else if (arr.isVector) {\n",
    "      sb.append(\"[\")\n",
    "      var i: Int = 0\n",
    "      while (i < arr.length) {\n",
    "        {\n",
    "          if (arr.isInstanceOf[IComplexNDArray]) sb.append(arr.asInstanceOf[IComplexNDArray].getComplex(i).toString)\n",
    "          else sb.append(String.format(\"%1$\" + padding + \"s\", decimalFormat.format(arr.getDouble(i))))\n",
    "          if (i < arr.length - 1) sb.append(sep)\n",
    "        }\n",
    "        {\n",
    "          i += 1; i - 1\n",
    "        }\n",
    "      }\n",
    "      sb.append(\"]\")\n",
    "      sb.toString\n",
    "    }\n",
    "    else {\n",
    "      offset = offset + 1\n",
    "      sb.append(\"[\")\n",
    "      var i: Int = 0\n",
    "      while (i < arr.slices) {\n",
    "        {\n",
    "          sb.append(format(arr.slice(i), rank - 1, offset))\n",
    "          if (i != arr.slices - 1) {\n",
    "            sb.append(\",\\n\")\n",
    "            sb.append(StringUtils.repeat(\"\\n\", rank - 2))\n",
    "            sb.append(StringUtils.repeat(\" \", offset))\n",
    "          }\n",
    "        }\n",
    "        {\n",
    "          i += 1; i - 1\n",
    "        }\n",
    "      }\n",
    "      sb.append(\"]\")\n",
    "      sb.toString\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mjava.io.{File, IOException}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.commons.io.FileUtils\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.net.URL\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.factory.Nd4j\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.records.reader.RecordReader\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.records.reader.impl.csv.CSVRecordReader\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.split.FileSplit\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.util.ClassPathResource\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.eval.Evaluation\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.MultiLayerConfiguration\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.NeuralNetConfiguration\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.layers.DenseLayer\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.layers.OutputLayer\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.multilayer.MultiLayerNetwork\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.weights.WeightInit\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.optimize.listeners.ScoreIterationListener\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.api.ndarray.INDArray\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.DataSet\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.SplitTestAndTrain\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.api.iterator.DataSetIterator\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.api.preprocessor.DataNormalization\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.api.preprocessor.NormalizerStandardize\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.lossfunctions.LossFunctions\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.slf4j.Logger\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.slf4j.LoggerFactory\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.reflections.Reflections\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.reflections.scanners.SubTypesScanner\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.util\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.common.data.NDArrayWritable\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.highcharts.SeriesType\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.Highcharts._\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.highcharts.Highchart\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.highcharts.Histogram\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.fasterxml.jackson.core.JsonParseException\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.fasterxml.jackson.databind.ObjectMapper\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.google.common.collect.{HashBasedTable, Table}\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mDeepLearning4JMultiLayerNetwork\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.io.{File, IOException}\n",
    "import org.apache.commons.io.FileUtils\n",
    "import java.net.URL\n",
    "import org.nd4j.linalg.factory.Nd4j\n",
    "import org.datavec.api.records.reader.RecordReader\n",
    "import org.datavec.api.records.reader.impl.csv.CSVRecordReader\n",
    "import org.datavec.api.split.FileSplit\n",
    "import org.datavec.api.util.ClassPathResource\n",
    "import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator\n",
    "import org.deeplearning4j.eval.Evaluation\n",
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration\n",
    "import org.deeplearning4j.nn.conf.layers.DenseLayer\n",
    "import org.deeplearning4j.nn.conf.layers.OutputLayer\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork\n",
    "import org.deeplearning4j.nn.weights.WeightInit\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "import org.nd4j.linalg.dataset.DataSet\n",
    "import org.nd4j.linalg.dataset.SplitTestAndTrain\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.NormalizerStandardize\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions\n",
    "import org.slf4j.Logger\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.reflections.Reflections\n",
    "import org.reflections.scanners.SubTypesScanner\n",
    "import java.util\n",
    "import org.datavec.common.data.NDArrayWritable\n",
    "import com.quantifind.charts.highcharts.SeriesType\n",
    "import com.quantifind.charts.Highcharts._\n",
    "import com.quantifind.charts.highcharts.Highchart\n",
    "import com.quantifind.charts.highcharts.Histogram\n",
    "import com.fasterxml.jackson.core.JsonParseException\n",
    "import com.fasterxml.jackson.databind.ObjectMapper\n",
    "import com.google.common.collect.{HashBasedTable, Table}\n",
    "\n",
    "class DeepLearning4JMultiLayerNetwork(val filePath: String) {\n",
    "\n",
    "  var dataFile: String = filePath\n",
    "\n",
    "  var series: Highchart = histogram(Seq(1, 2, 2, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 6, 7), 7)\n",
    "\n",
    "  def execute() {\n",
    "    System.out.println(\"Hello, deeplearning4j!\")\n",
    "\n",
    "    //verify that nd4j is working\n",
    "    val arr: INDArray = Nd4j.create(Array[Float](1f, 20000000f, 40.838383f, 3f), Array[Int](2, 2))\n",
    "    System.out.println(arr.toString)\n",
    "\n",
    "    //First: get the dataset using the record reader. CSVRecordReader handles loading/parsing\n",
    "    val numLinesToSkip: Int = 0\n",
    "    val delimiter: String = \",\"\n",
    "    val recordReader: RecordReader = new CSVRecordReader(numLinesToSkip, delimiter)\n",
    "    recordReader.initialize(new FileSplit(new File(dataFile)))\n",
    "\n",
    "    //Second: the RecordReaderDataSetIterator handles conversion to DataSet objects, ready for use in neural network\n",
    "    val labelIndex: Int = 4 //5 values in each row of the iris.txt CSV: 4 input features followed by an integer label (class) index. Labels are the 5th value (index 4) in each row\n",
    "    val numClasses: Int = 3 //3 classes (types of iris flowers) in the iris data set. Classes have integer values 0, 1 or 2\n",
    "    val batchSize: Int = 150 //Iris data set: 150 examples total. We are loading all of them into one DataSet (not recommended for large data sets)\n",
    "\n",
    "    val iterator: DataSetIterator = new RecordReaderDataSetIterator(recordReader, batchSize, labelIndex, numClasses)\n",
    "\n",
    "    val allData: DataSet = iterator.next\n",
    "    allData.shuffle()\n",
    "    val testAndTrain: SplitTestAndTrain = allData.splitTestAndTrain(0.65) //Use 65% of data for training\n",
    "    val trainingData: DataSet = testAndTrain.getTrain\n",
    "    val testData: DataSet = testAndTrain.getTest\n",
    "\n",
    "    //We need to normalize our data. We'll use NormalizeStandardize (which gives us mean 0, unit variance):\n",
    "    val normalizer: DataNormalization = new NormalizerStandardize\n",
    "    normalizer.fit(trainingData) //Collect the statistics (mean/stdev) from the training data. This does not modify the input data\n",
    "    normalizer.transform(trainingData) //Apply normalization to the training data\n",
    "    normalizer.transform(testData) //Apply normalization to the test data. This is using statistics calculated from the *training* set\n",
    "    val numInputs: Int = 4\n",
    "    val outputNum: Int = 3\n",
    "    val iterations: Int = 1000\n",
    "    val seed: Long = 6\n",
    "\n",
    "    System.out.println(\"Build model....\")\n",
    "    val conf: MultiLayerConfiguration =\n",
    "      new NeuralNetConfiguration.Builder().seed(seed)\n",
    "        .iterations(iterations).activation(\"tanh\")\n",
    "        .weightInit(WeightInit.XAVIER).learningRate(0.1)\n",
    "        .regularization(true).l2(1e-4).list\n",
    "        .layer(0, new DenseLayer.Builder().nIn(numInputs).nOut(3).build)\n",
    "        .layer(1, new DenseLayer.Builder().nIn(3).nOut(3).build)\n",
    "        .layer(2, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "          .activation(\"softmax\")\n",
    "          .nIn(3).nOut(outputNum).build).backprop(true).pretrain(false).build\n",
    "\n",
    "    //run the model\n",
    "    val model: MultiLayerNetwork = new MultiLayerNetwork(conf)\n",
    "    model.init()\n",
    "    model.setListeners(new ScoreIterationListener(100))\n",
    "\n",
    "    model.fit(trainingData)\n",
    "\n",
    "    //evaluate the model on the test set\n",
    "    val eval: Evaluation = new Evaluation(3)\n",
    "    val output: INDArray = model.output(testData.getFeatureMatrix)\n",
    "    eval.eval(testData.getLabels, output)\n",
    "    System.out.println(eval.stats)\n",
    "    \n",
    "    val table: Table[Integer, Integer, Double] = makeTableFromArray(output,3)\n",
    "    System.out.println(table)   \n",
    "\n",
    "    series = histogram(Seq(8, 14, 3, 23), 4)\n",
    "  }\n",
    "\n",
    "\n",
    "  @throws[IOException]\n",
    "  def makeRowsFromNDArray(source: INDArray, precision: Int): util.List[_] = {\n",
    "    val mapper: ObjectMapper = new ObjectMapper\n",
    "    val serializedData: String = new NDArrayStrings(\",\", precision, \"######0\").format(source)\n",
    "    try {\n",
    "      val rows: util.List[_] = mapper.readValue(serializedData.getBytes, classOf[util.List[_]]).asInstanceOf[util.List[_]]\n",
    "      rows\n",
    "    }\n",
    "    catch {\n",
    "      case e: JsonParseException => {\n",
    "        e.printStackTrace()\n",
    "        return null\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  @throws[IOException]\n",
    "  def makeTableFromArray(source: INDArray, precision: Int): Table[Integer, Integer, Double] = {\n",
    "    val table: Table[Integer, Integer, Double] = HashBasedTable.create[Integer, Integer, Double]\n",
    "    val rows: util.List[_] = makeRowsFromNDArray(source, precision)\n",
    "    var i: Int = 0\n",
    "    while (i < rows.size) {\n",
    "      {\n",
    "        val row: util.List[Double] = rows.get(i).asInstanceOf[util.List[Double]]\n",
    "        var j: Int = 0\n",
    "        while (j < row.size) {\n",
    "          {\n",
    "            table.put(i, j, row.get(j))\n",
    "          }\n",
    "          {\n",
    "            j += 1; j - 1\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      {\n",
    "        i += 1; i - 1\n",
    "      }\n",
    "    }\n",
    "    table\n",
    "  }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to http://77740977d776:33252 (CMD + Click link in Mac OSX).\n",
      "Hello, deeplearning4j!\n",
      "[[         1.00, 20,000,000.00],\n",
      " [        40.84,          3.00]]\n",
      "Build model....\n",
      "\n",
      "Examples labeled as 0 classified by model as 0: 10 times\n",
      "Examples labeled as 0 classified by model as 1: 1 times\n",
      "Examples labeled as 1 classified by model as 1: 17 times\n",
      "Examples labeled as 2 classified by model as 2: 25 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " Accuracy:  0.9811\n",
      " Precision: 0.9815\n",
      " Recall:    0.9697\n",
      " F1 Score:  0.9756\n",
      "========================================================================\n",
      "[[0.00, 0.98, 0.02],\n",
      " [0.00, 0.10, 0.90],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.00, 0.27, 0.73],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.00, 0.02, 0.98],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.00, 0.02, 0.98],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.00, 0.03, 0.97],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.00, 0.03, 0.97],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.01, 0.97, 0.02],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.00, 0.04, 0.96],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.01, 0.99, 0.01],\n",
      " [0.00, 0.14, 0.86],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.49, 0.51, 0.00],\n",
      " [0.00, 0.38, 0.62],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.00, 0.02, 0.98],\n",
      " [0.00, 0.28, 0.72],\n",
      " [0.00, 0.02, 0.98],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.01, 0.99, 0.01],\n",
      " [0.00, 0.03, 0.97],\n",
      " [0.00, 0.23, 0.77],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.99, 0.01, 0.00],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.01, 0.99, 0.01],\n",
      " [0.01, 0.98, 0.02],\n",
      " [0.00, 0.02, 0.98],\n",
      " [0.01, 0.98, 0.01],\n",
      " [0.00, 0.01, 0.99],\n",
      " [0.01, 0.98, 0.01]]\n",
      "{0={0=0.005, 1=0.98, 2=0.015}, 1={0=0.0, 1=0.099, 2=0.901}, 2={0=0.0, 1=0.013, 2=0.987}, 3={0=0.994, 1=0.006, 2=0.0}, 4={0=0.992, 1=0.008, 2=0.0}, 5={0=0.006, 1=0.981, 2=0.013}, 6={0=0.992, 1=0.008, 2=0.0}, 7={0=0.013, 1=0.979, 2=0.009}, 8={0=0.0, 1=0.012, 2=0.988}, 9={0=0.994, 1=0.006, 2=0.0}, 10={0=0.001, 1=0.27, 2=0.729}, 11={0=0.014, 1=0.978, 2=0.008}, 12={0=0.0, 1=0.018, 2=0.982}, 13={0=0.007, 1=0.984, 2=0.009}, 14={0=0.0, 1=0.015, 2=0.985}, 15={0=0.006, 1=0.983, 2=0.011}, 17={0=0.0, 1=0.026, 2=0.974}, 16={0=0.006, 1=0.982, 2=0.012}, 19={0=0.0, 1=0.026, 2=0.974}, 18={0=0.007, 1=0.985, 2=0.008}, 21={0=0.0, 1=0.013, 2=0.987}, 20={0=0.994, 1=0.006, 2=0.0}, 23={0=0.007, 1=0.973, 2=0.02}, 22={0=0.0, 1=0.014, 2=0.985}, 25={0=0.0, 1=0.013, 2=0.987}, 24={0=0.0, 1=0.013, 2=0.987}, 27={0=0.992, 1=0.008, 2=0.0}, 26={0=0.0, 1=0.035, 2=0.965}, 29={0=0.0, 1=0.142, 2=0.857}, 28={0=0.007, 1=0.985, 2=0.008}, 31={0=0.0, 1=0.015, 2=0.985}, 30={0=0.994, 1=0.006, 2=0.0}, 34={0=0.006, 1=0.984, 2=0.01}, 35={0=0.0, 1=0.019, 2=0.981}, 32={0=0.49, 1=0.507, 2=0.004}, 33={0=0.001, 1=0.38, 2=0.619}, 38={0=0.0, 1=0.013, 2=0.987}, 39={0=0.992, 1=0.008, 2=0.0}, 36={0=0.001, 1=0.279, 2=0.72}, 37={0=0.0, 1=0.018, 2=0.982}, 42={0=0.001, 1=0.226, 2=0.774}, 43={0=0.994, 1=0.006, 2=0.0}, 40={0=0.006, 1=0.986, 2=0.008}, 41={0=0.0, 1=0.031, 2=0.969}, 46={0=0.0, 1=0.014, 2=0.986}, 47={0=0.007, 1=0.985, 2=0.008}, 44={0=0.007, 1=0.981, 2=0.011}, 45={0=0.994, 1=0.006, 2=0.0}, 51={0=0.0, 1=0.013, 2=0.987}, 50={0=0.007, 1=0.984, 2=0.009}, 49={0=0.0, 1=0.022, 2=0.978}, 48={0=0.005, 1=0.977, 2=0.018}, 52={0=0.006, 1=0.984, 2=0.01}}\n",
      "Output written to http://77740977d776:33252 (CMD + Click link in Mac OSX).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnetwork\u001b[0m: INSTANCE.$ref$DeepLearning4JMultiLayerNetwork = cmd92$$user$DeepLearning4JMultiLayerNetwork@64827b03"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val network = new DeepLearning4JMultiLayerNetwork(\"data/iris.txt\");\n",
    "network.execute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction \u001b[36mshow\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def show(c:Highchart, name:String) = {\n",
    "    val json = s\"\"\"\n",
    "$$(function () {\n",
    "    $$('#$name').highcharts(${c.toJson})\n",
    "    })\n",
    "\"\"\"\n",
    "    display.html(<div id={name}>graph</div>)\n",
    "    display.js(json)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <script src=\"http://code.highcharts.com/stock/highstock.js\"></script>\n",
       "  <script src=\"http://code.highcharts.com/stock/modules/exporting.js\"></script>\n",
       "  <script src=\"http://www.highcharts.com/js/themes/grid.js\"></script>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.html(\n",
    "<div>\n",
    "  <script src=\"http://code.highcharts.com/stock/highstock.js\"></script>\n",
    "  <script src=\"http://code.highcharts.com/stock/modules/exporting.js\"></script>\n",
    "  <script src=\"http://www.highcharts.com/js/themes/grid.js\"></script>\n",
    "</div>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"graph\">graph</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "$(function () {\n",
       "    $('#graph').highcharts({\"series\":[{\"data\":[{\"x\":0,\"y\":2.0,\"name\":\"3.00 - 9.25\"},{\"x\":1,\"y\":1.0,\"name\":\"9.25 - 15.50\"},{\"x\":2,\"y\":0.0,\"name\":\"15.50 - 21.75\"},{\"x\":3,\"y\":1.0,\"name\":\"21.75 - 28.00\"}],\"type\":\"column\"}],\"exporting\":{\"filename\":\"chart\"},\"yAxis\":[{\"title\":{\"text\":\"\"}}],\"plotOptions\":{\"series\":{\"groupPadding\":0,\"pointPadding\":0},\"column\":{\"turboThreshold\":0}},\"credits\":{\"href\":\"\",\"text\":\"\"},\"chart\":{\"zoomType\":\"xy\"},\"title\":{\"text\":\"\"},\"xAxis\":[{\"categories\":[\"3.00 - 9.25\",\"9.25 - 15.50\",\"15.50 - 21.75\",\"21.75 - 28.00\"],\"title\":{\"text\":\"\"},\"labels\":{\"rotation\":-45}}]})\n",
       "    })\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(network.series, \"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala210",
   "name": "scala210"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala210",
   "pygments_lexer": "scala",
   "version": "2.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
