{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.addPath(\"/opt/app/libs/datavec-api-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/annotations-2.0.1.jar\")                \n",
    "classpath.addPath(\"/opt/app/libs/commons-io-2.4.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-0.5.0-linux-x86_64.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/commons-lang3-3.3.1.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/commons-math3-3.4.1.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/guava-18.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/javacpp-1.2.3.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-api-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/javassist-3.18.2-GA.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-native-platform-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/lombok-1.16.4.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/reflections-0.9.10.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-api-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/scala-library-2.11.1.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-buffer-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/slf4j-api-1.7.21.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-common-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/slf4j-simple-1.7.21.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/nd4j-context-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/deeplearning4j-core-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/canova-api-0.0.0.17.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/hadoop-mapreduce-client-core-2.2.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/datavec-nd4j-common-0.5.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/reflections-0.9.10.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-dataformat-yaml-2.4.4.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/guava-18.0.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-core-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-annotations-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-databind-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/jackson-module-scala_2.10-2.6.5.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/json4s-jackson_2.10-3.2.11.jar\")\n",
    "classpath.addPath(\"/opt/app/libs/commons-lang-2.5.jar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0 artifact(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classpath.add(\"com.quantifind\" %% \"wisp\" % \"0.0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mjava.text.{DecimalFormat, DecimalFormatSymbols}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.commons.lang.StringUtils\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.api.complex.IComplexNDArray\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.api.ndarray.INDArray\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mNDArrayStrings\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.text.{DecimalFormat, DecimalFormatSymbols}\n",
    "\n",
    "import org.apache.commons.lang.StringUtils\n",
    "import org.nd4j.linalg.api.complex.IComplexNDArray\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "\n",
    "/**\n",
    "  * Created by claytongraham on 10/29/16.\n",
    "  */\n",
    "class NDArrayStrings {\n",
    "  private var sep: String = \",\"\n",
    "  private var padding: Int = 0\n",
    "  private var decFormatNum: String = \"#,###,##0\"\n",
    "  private var decFormatRest: String = \"\"\n",
    "  private var decimalFormat: DecimalFormat = new DecimalFormat(decFormatNum + decFormatRest)\n",
    "\n",
    "  def this(sep: String, precisionI: Int, decFormat: String) {\n",
    "    this()\n",
    "    this.decFormatNum = decFormat\n",
    "    this.sep = sep\n",
    "    var precision: Int = precisionI\n",
    "\n",
    "    if (precision != 0) {\n",
    "      this.decFormatRest = \".\"\n",
    "      while (precision > 0) {\n",
    "        this.decFormatRest += \"0\"\n",
    "        precision -= 1\n",
    "      }\n",
    "    }\n",
    "    this.decimalFormat = new DecimalFormat(decFormatNum + decFormatRest)\n",
    "    val sepNgroup: DecimalFormatSymbols = DecimalFormatSymbols.getInstance\n",
    "    sepNgroup.setDecimalSeparator('.')\n",
    "    sepNgroup.setGroupingSeparator(',')\n",
    "    decimalFormat.setDecimalFormatSymbols(sepNgroup)\n",
    "  }\n",
    "\n",
    "  /**\n",
    "    * Format the given ndarray as a string\n",
    "    *\n",
    "    * @param arr the array to format\n",
    "    * @return the formatted array\n",
    "    */\n",
    "  def format(arr: INDArray): String = {\n",
    "    val padding: String = decimalFormat.format(arr.maxNumber)\n",
    "    this.padding = padding.length\n",
    "    format(arr, arr.rank)\n",
    "  }\n",
    "\n",
    "  private def format(arr: INDArray, rank: Int): String = format(arr, arr.rank, 0)\n",
    "\n",
    "  private def format(arr: INDArray, rank: Int, offsetI: Int): String = {\n",
    "    val sb: StringBuilder = new StringBuilder\n",
    "    var offset: Int = offsetI\n",
    "    if (arr.isScalar) {\n",
    "      if (arr.isInstanceOf[IComplexNDArray]) return arr.asInstanceOf[IComplexNDArray].getComplex(0).toString\n",
    "      decimalFormat.format(arr.getDouble(0))\n",
    "    }\n",
    "    else if (rank <= 0) \"\"\n",
    "    else if (arr.isVector) {\n",
    "      sb.append(\"[\")\n",
    "      var i: Int = 0\n",
    "      while (i < arr.length) {\n",
    "        {\n",
    "          if (arr.isInstanceOf[IComplexNDArray]) sb.append(arr.asInstanceOf[IComplexNDArray].getComplex(i).toString)\n",
    "          else sb.append(String.format(\"%1$\" + padding + \"s\", decimalFormat.format(arr.getDouble(i))))\n",
    "          if (i < arr.length - 1) sb.append(sep)\n",
    "        }\n",
    "        {\n",
    "          i += 1; i - 1\n",
    "        }\n",
    "      }\n",
    "      sb.append(\"]\")\n",
    "      sb.toString\n",
    "    }\n",
    "    else {\n",
    "      offset = offset + 1\n",
    "      sb.append(\"[\")\n",
    "      var i: Int = 0\n",
    "      while (i < arr.slices) {\n",
    "        {\n",
    "          sb.append(format(arr.slice(i), rank - 1, offset))\n",
    "          if (i != arr.slices - 1) {\n",
    "            sb.append(\",\\n\")\n",
    "            sb.append(StringUtils.repeat(\"\\n\", rank - 2))\n",
    "            sb.append(StringUtils.repeat(\" \", offset))\n",
    "          }\n",
    "        }\n",
    "        {\n",
    "          i += 1; i - 1\n",
    "        }\n",
    "      }\n",
    "      sb.append(\"]\")\n",
    "      sb.toString\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mjava.io.{File, IOException}\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.apache.commons.io.FileUtils\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.net.URL\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.factory.Nd4j\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.records.reader.RecordReader\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.records.reader.impl.csv.CSVRecordReader\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.split.FileSplit\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.api.util.ClassPathResource\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.eval.Evaluation\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.MultiLayerConfiguration\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.NeuralNetConfiguration\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.layers.DenseLayer\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.conf.layers.OutputLayer\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.multilayer.MultiLayerNetwork\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.nn.weights.WeightInit\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.deeplearning4j.optimize.listeners.ScoreIterationListener\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.api.ndarray.INDArray\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.DataSet\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.SplitTestAndTrain\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.api.iterator.DataSetIterator\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.api.preprocessor.DataNormalization\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.dataset.api.preprocessor.NormalizerStandardize\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.nd4j.linalg.lossfunctions.LossFunctions\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.slf4j.Logger\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.slf4j.LoggerFactory\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.reflections.Reflections\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.reflections.scanners.SubTypesScanner\u001b[0m\n",
       "\u001b[32mimport \u001b[36mjava.util\u001b[0m\n",
       "\u001b[32mimport \u001b[36morg.datavec.common.data.NDArrayWritable\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.fasterxml.jackson.core.JsonParseException\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.fasterxml.jackson.databind.ObjectMapper\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.google.common.collect.{HashBasedTable, Table}\u001b[0m\n",
       "defined \u001b[32mclass \u001b[36mDeepLearning4JMultiLayerNetwork\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import java.io.{File, IOException}\n",
    "import org.apache.commons.io.FileUtils\n",
    "import java.net.URL\n",
    "import org.nd4j.linalg.factory.Nd4j\n",
    "import org.datavec.api.records.reader.RecordReader\n",
    "import org.datavec.api.records.reader.impl.csv.CSVRecordReader\n",
    "import org.datavec.api.split.FileSplit\n",
    "import org.datavec.api.util.ClassPathResource\n",
    "import org.deeplearning4j.datasets.datavec.RecordReaderDataSetIterator\n",
    "import org.deeplearning4j.eval.Evaluation\n",
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration\n",
    "import org.deeplearning4j.nn.conf.layers.DenseLayer\n",
    "import org.deeplearning4j.nn.conf.layers.OutputLayer\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork\n",
    "import org.deeplearning4j.nn.weights.WeightInit\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener\n",
    "import org.nd4j.linalg.api.ndarray.INDArray\n",
    "import org.nd4j.linalg.dataset.DataSet\n",
    "import org.nd4j.linalg.dataset.SplitTestAndTrain\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.DataNormalization\n",
    "import org.nd4j.linalg.dataset.api.preprocessor.NormalizerStandardize\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions\n",
    "import org.slf4j.Logger\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.reflections.Reflections\n",
    "import org.reflections.scanners.SubTypesScanner\n",
    "import java.util\n",
    "import org.datavec.common.data.NDArrayWritable\n",
    "import com.fasterxml.jackson.core.JsonParseException\n",
    "import com.fasterxml.jackson.databind.ObjectMapper\n",
    "import com.google.common.collect.{HashBasedTable, Table}\n",
    "\n",
    "class DeepLearning4JMultiLayerNetwork(val filePath: String) {\n",
    "\n",
    "  var dataFile: String = filePath\n",
    "\n",
    "  var networkOutput: Table[Integer, Integer, Double] = null\n",
    "  \n",
    "  def execute() {\n",
    "    System.out.println(\"Hello, deeplearning4j!\")\n",
    "\n",
    "    //verify that nd4j is working\n",
    "    val arr: INDArray = Nd4j.create(Array[Float](1f, 20000000f, 40.838383f, 3f), Array[Int](2, 2))\n",
    "    System.out.println(arr.toString)\n",
    "\n",
    "    //First: get the dataset using the record reader. CSVRecordReader handles loading/parsing\n",
    "    val numLinesToSkip: Int = 0\n",
    "    val delimiter: String = \",\"\n",
    "    val recordReader: RecordReader = new CSVRecordReader(numLinesToSkip, delimiter)\n",
    "    recordReader.initialize(new FileSplit(new File(dataFile)))\n",
    "\n",
    "    //Second: the RecordReaderDataSetIterator handles conversion to DataSet objects, ready for use in neural network\n",
    "    val labelIndex: Int = 4 //5 values in each row of the iris.txt CSV: 4 input features followed by an integer label (class) index. Labels are the 5th value (index 4) in each row\n",
    "    val numClasses: Int = 3 //3 classes (types of iris flowers) in the iris data set. Classes have integer values 0, 1 or 2\n",
    "    val batchSize: Int = 150 //Iris data set: 150 examples total. We are loading all of them into one DataSet (not recommended for large data sets)\n",
    "\n",
    "    val iterator: DataSetIterator = new RecordReaderDataSetIterator(recordReader, batchSize, labelIndex, numClasses)\n",
    "\n",
    "    val allData: DataSet = iterator.next\n",
    "    allData.shuffle()\n",
    "    val testAndTrain: SplitTestAndTrain = allData.splitTestAndTrain(0.65) //Use 65% of data for training\n",
    "    val trainingData: DataSet = testAndTrain.getTrain\n",
    "    val testData: DataSet = testAndTrain.getTest\n",
    "\n",
    "    //We need to normalize our data. We'll use NormalizeStandardize (which gives us mean 0, unit variance):\n",
    "    val normalizer: DataNormalization = new NormalizerStandardize\n",
    "    normalizer.fit(trainingData) //Collect the statistics (mean/stdev) from the training data. This does not modify the input data\n",
    "    normalizer.transform(trainingData) //Apply normalization to the training data\n",
    "    normalizer.transform(testData) //Apply normalization to the test data. This is using statistics calculated from the *training* set\n",
    "    val numInputs: Int = 4\n",
    "    val outputNum: Int = 3\n",
    "    val iterations: Int = 1000\n",
    "    val seed: Long = 6\n",
    "\n",
    "    System.out.println(\"Build model....\")\n",
    "    val conf: MultiLayerConfiguration =\n",
    "      new NeuralNetConfiguration.Builder().seed(seed)\n",
    "        .iterations(iterations).activation(\"tanh\")\n",
    "        .weightInit(WeightInit.XAVIER).learningRate(0.1)\n",
    "        .regularization(true).l2(1e-4).list\n",
    "        .layer(0, new DenseLayer.Builder().nIn(numInputs).nOut(3).build)\n",
    "        .layer(1, new DenseLayer.Builder().nIn(3).nOut(3).build)\n",
    "        .layer(2, new OutputLayer.Builder(LossFunctions.LossFunction.NEGATIVELOGLIKELIHOOD)\n",
    "          .activation(\"softmax\")\n",
    "          .nIn(3).nOut(outputNum).build).backprop(true).pretrain(false).build\n",
    "\n",
    "    //run the model\n",
    "    val model: MultiLayerNetwork = new MultiLayerNetwork(conf)\n",
    "    model.init()\n",
    "    model.setListeners(new ScoreIterationListener(100))\n",
    "    model.fit(trainingData)\n",
    "\n",
    "    //evaluate the model on the test set\n",
    "    val eval: Evaluation = new Evaluation(3)\n",
    "    val output: INDArray = model.output(testData.getFeatureMatrix)\n",
    "    eval.eval(testData.getLabels, output)\n",
    "    System.out.println(eval.stats)\n",
    "    \n",
    "    networkOutput = makeTableFromArray(output,3)\n",
    "    \n",
    "  }\n",
    "\n",
    "\n",
    "  @throws[IOException]\n",
    "  def makeRowsFromNDArray(source: INDArray, precision: Int): util.List[_] = {\n",
    "    val mapper: ObjectMapper = new ObjectMapper\n",
    "    val serializedData: String = new NDArrayStrings(\",\", precision, \"######0\").format(source)\n",
    "    try {\n",
    "      val rows: util.List[_] = mapper.readValue(serializedData.getBytes, classOf[util.List[_]]).asInstanceOf[util.List[_]]\n",
    "      rows\n",
    "    }\n",
    "    catch {\n",
    "      case e: JsonParseException => {\n",
    "        e.printStackTrace()\n",
    "        return null\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  @throws[IOException]\n",
    "  def makeTableFromArray(source: INDArray, precision: Int): Table[Integer, Integer, Double] = {\n",
    "    val table: Table[Integer, Integer, Double] = HashBasedTable.create[Integer, Integer, Double]\n",
    "    val rows: util.List[_] = makeRowsFromNDArray(source, precision)\n",
    "    var i: Int = 0\n",
    "    while (i < rows.size) {\n",
    "      {\n",
    "        val row: util.List[Double] = rows.get(i).asInstanceOf[util.List[Double]]\n",
    "        var j: Int = 0\n",
    "        while (j < row.size) {\n",
    "          {\n",
    "            table.put(i, j, row.get(j))\n",
    "          }\n",
    "          {\n",
    "            j += 1; j - 1\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      {\n",
    "        i += 1; i - 1\n",
    "      }\n",
    "    }\n",
    "    table\n",
    "  }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, deeplearning4j!\n",
      "[[         1.00, 20,000,000.00],\n",
      " [        40.84,          3.00]]\n",
      "Build model....\n",
      "\n",
      "Examples labeled as 0 classified by model as 0: 10 times\n",
      "Examples labeled as 0 classified by model as 1: 1 times\n",
      "Examples labeled as 1 classified by model as 1: 16 times\n",
      "Examples labeled as 2 classified by model as 1: 3 times\n",
      "Examples labeled as 2 classified by model as 2: 23 times\n",
      "\n",
      "\n",
      "==========================Scores========================================\n",
      " Accuracy:  0.9245\n",
      " Precision: 0.9333\n",
      " Recall:    0.9312\n",
      " F1 Score:  0.9323\n",
      "========================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mnetwork\u001b[0m: INSTANCE.$ref$DeepLearning4JMultiLayerNetwork = cmd30$$user$DeepLearning4JMultiLayerNetwork@76fd543a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val network = new DeepLearning4JMultiLayerNetwork(\"data/iris.txt\");\n",
    "network.execute() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.highcharts.SeriesType\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.Highcharts._\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.highcharts.Highchart\u001b[0m\n",
       "\u001b[32mimport \u001b[36mcom.quantifind.charts.highcharts.Histogram\u001b[0m\n",
       "defined \u001b[32mfunction \u001b[36mshow\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import com.quantifind.charts.highcharts.SeriesType\n",
    "import com.quantifind.charts.Highcharts._\n",
    "import com.quantifind.charts.highcharts.Highchart\n",
    "import com.quantifind.charts.highcharts.Histogram\n",
    "\n",
    "def show(c:Highchart, name:String) = {\n",
    "    val json = s\"\"\"\n",
    "$$(function () {\n",
    "    $$('#$name').highcharts(${c.toJson})\n",
    "    })\n",
    "\"\"\"\n",
    "    display.html(<div id={name}>graph</div>)\n",
    "    display.js(json)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <script src=\"http://code.highcharts.com/stock/highstock.js\"></script>\n",
       "  <script src=\"http://code.highcharts.com/stock/modules/exporting.js\"></script>\n",
       "  <script src=\"http://www.highcharts.com/js/themes/grid.js\"></script>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display.html(\n",
    "<div>\n",
    "  <script src=\"http://code.highcharts.com/stock/highstock.js\"></script>\n",
    "  <script src=\"http://code.highcharts.com/stock/modules/exporting.js\"></script>\n",
    "  <script src=\"http://www.highcharts.com/js/themes/grid.js\"></script>\n",
    "</div>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output written to http://a0973adcac54:45464 (CMD + Click link in Mac OSX)."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"graph\">graph</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "$(function () {\n",
       "    $('#graph').highcharts({\"series\":[{\"data\":[{\"x\":0,\"y\":1.0,\"name\":\"1.00 - 1.86\"},{\"x\":1,\"y\":2.0,\"name\":\"1.86 - 2.71\"},{\"x\":2,\"y\":2.0,\"name\":\"2.71 - 3.57\"},{\"x\":3,\"y\":5.0,\"name\":\"3.57 - 4.43\"},{\"x\":4,\"y\":3.0,\"name\":\"4.43 - 5.29\"},{\"x\":5,\"y\":1.0,\"name\":\"5.29 - 6.14\"},{\"x\":6,\"y\":0.0,\"name\":\"6.14 - 7.00\"},{\"x\":7,\"y\":1.0,\"name\":\"7.00 - 7.86\"}],\"type\":\"column\"}],\"exporting\":{\"filename\":\"chart\"},\"yAxis\":[{\"title\":{\"text\":\"\"}}],\"plotOptions\":{\"series\":{\"groupPadding\":0,\"pointPadding\":0},\"column\":{\"turboThreshold\":0}},\"credits\":{\"href\":\"\",\"text\":\"\"},\"chart\":{\"zoomType\":\"xy\"},\"title\":{\"text\":\"\"},\"xAxis\":[{\"categories\":[\"1.00 - 1.86\",\"1.86 - 2.71\",\"2.71 - 3.57\",\"3.57 - 4.43\",\"4.43 - 5.29\",\"5.29 - 6.14\",\"6.14 - 7.00\",\"7.00 - 7.86\"],\"title\":{\"text\":\"\"},\"labels\":{\"rotation\":-45}}]})\n",
       "    })\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mchart\u001b[0m: com.quantifind.charts.highcharts.Highchart = \u001b[33mHighchart\u001b[0m(\n",
       "  \u001b[33mList\u001b[0m(\n",
       "    \u001b[33mSeries\u001b[0m(\n",
       "      \u001b[33mArrayBuffer\u001b[0m(\n",
       "        Data(0,1.0,None,Some(1.00 - 1.86)),\n",
       "        Data(1,2.0,None,Some(1.86 - 2.71)),\n",
       "        Data(2,2.0,None,Some(2.71 - 3.57)),\n",
       "        Data(3,5.0,None,Some(3.57 - 4.43)),\n",
       "        Data(4,3.0,None,Some(4.43 - 5.29)),\n",
       "        Data(5,1.0,None,Some(5.29 - 6.14)),\n",
       "        Data(6,0.0,None,Some(6.14 - 7.00)),\n",
       "        Data(7,1.0,None,Some(7.00 - 7.86))\n",
       "      ),\n",
       "      None,\n",
       "      None,\n",
       "      None,\n",
       "      \u001b[33mSome\u001b[0m(\u001b[32m\"column\"\u001b[0m),\n",
       "      None,\n",
       "      None,\n",
       "      None,\n",
       "\u001b[33m...\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val chart = histogram(Seq(1, 2, 2, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 6, 7), 7)\n",
    "show(chart, \"graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.10",
   "language": "scala210",
   "name": "scala210"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala210",
   "pygments_lexer": "scala",
   "version": "2.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
